# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Mq0kNzY1cBMVfkDCC8JD-knfmbB4HtK
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from keras.datasets import mnist
import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
import glob
from PIL import Image
import gzip
import os
import requests 
from sklearn.svm import SVC, LinearSVC
from google.colab import drive
drive.mount('/content/drive')
from sklearn.metrics import confusion_matrix
import sklearn.metrics as metrics
from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_curve
from sklearn.preprocessing import label_binarize
from sklearn.metrics import auc
import matplotlib.pyplot as plt
from scipy import interp
from itertools import cycle
from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import cv2 as cv
from sklearn.model_selection import cross_validate

!pip install unrar

"""# **Section 1**

## **Functions**
"""

def generate_binary_dataset(min_value, max_value, size, positive_condition):
    data = pd.DataFrame(np.concatenate((np.random.uniform(min_value, max_value, (size, 2)),-np.ones((size, 1))), axis=1),  columns=['x', 'y', 'target'])
    data.loc[positive_condition(data.x, data.y), 'target'] = 1
    return data

def plot_separator(svc):
    ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()
    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T
    Z = svc.decision_function(xy).reshape(XX.shape)
    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])
    ax.scatter(svc.support_vectors_[:, 0], svc.support_vectors_[:, 1], s=100, linewidth=1, label="support vectors", facecolors='none', edgecolors='k')

def plot_binary(data, svc=None):
    plt.figure(figsize=(15, 15))
    plt.scatter(data.x, data.y, c=data.target, label="data", s=20, cmap=plt.cm.seismic)
    
    if svc:
        plot_separator(svc)
    
    plt.grid()
    plt.legend()

"""## **Example 1**

### **data**
"""

dataset = generate_binary_dataset(-10, 10, 1000, lambda x, y: x  > y)
dataset.head()

plot_binary(dataset)

"""### **Linear**"""

model = SVC(kernel="linear")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **rbf**"""

model = SVC(kernel='rbf')
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 2** """

model = SVC(kernel='poly', degree=2, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 3**"""

model = SVC(kernel='poly', degree=3, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **sigmoid**"""

model = SVC(kernel="sigmoid")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""## **Example 2**

### **data**
"""

dataset = generate_binary_dataset(-2, 2, 2000, lambda x, y: x ** 2 + y ** 2 < 1)
dataset.head()

plot_binary(dataset)

"""### **linear**"""

model = SVC(kernel="linear")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **rbf**"""

model = SVC(kernel='rbf')
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 2**"""

model = SVC(kernel='poly', degree=2, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 3**"""

model = SVC(kernel='poly', degree=3, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **sigmoid**"""

model = SVC(kernel="sigmoid")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""## **Example 3**

### **data**
"""

dataset = generate_binary_dataset(-5, 5, 2000, lambda x, y: x ** 2 +  y**3 > 2)
dataset.head()
plot_binary(dataset)

"""### **linear**"""

model = SVC(kernel="linear")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **rbf**"""

model = SVC(kernel='rbf')
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 2**"""

model = SVC(kernel='poly', degree=2, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 3**"""

model = SVC(kernel='poly', degree=3, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **sigmoid**"""

model = SVC(kernel="sigmoid")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""## **Example4**

### **data**
"""

dataset = generate_binary_dataset(-10, 10, 1000, lambda x, y: x ** 2 - y**2 > 0)
dataset.head()
plot_binary(dataset)

"""### **linear**"""

model = SVC(kernel="linear")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **rbf**"""

model = SVC(kernel="rbf")
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 2**"""

model = SVC(kernel='poly', degree=2, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **poly degree = 3**"""

model = SVC(kernel='poly', degree=3, tol=1e-3)
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""### **sigmoid**"""

model = SVC(kernel='sigmoid')
model.fit(dataset[['x', 'y']], dataset.target)
model.score(dataset[['x', 'y']], dataset.target)

plot_binary(dataset, model)

"""# **Section 2**

### **data**
"""

def load_mnist(train_data=True, test_data=False):
    RESOURCES = [
        'train-images-idx3-ubyte.gz',
        'train-labels-idx1-ubyte.gz',
        't10k-images-idx3-ubyte.gz',
        't10k-labels-idx1-ubyte.gz']
    if (os.path.isdir('data') == 0):
        os.mkdir('data')
    if (os.path.isdir('data/mnist') == 0):
        os.mkdir('data/mnist')
    for name in RESOURCES:
        if (os.path.isfile('data/mnist/'+name) == 0):
            url = 'http://yann.lecun.com/exdb/mnist/'+name
            r = requests.get(url, allow_redirects=True)
            open('data/mnist/'+name, 'wb').write(r.content)
    return get_images(train_data, test_data), get_labels(train_data, test_data)
    #train_data = get_images(train_data)
    #test_data = get_images(test_data)
    #train_lable = get_labels(train_data)
    #test_lable = get_labels(test_data)
    #return train_data, test_data, train_lable, test_lable

def get_images(train_data=True, test_data=False):
    to_return = []
    if train_data:
        with gzip.open('data/mnist/train-images-idx3-ubyte.gz', 'r') as f:
            # first 4 bytes is a magic number
            magic_number = int.from_bytes(f.read(4), 'big')
            # second 4 bytes is the number of images
            image_count = int.from_bytes(f.read(4), 'big')
            # third 4 bytes is the row count
            row_count = int.from_bytes(f.read(4), 'big')
            # fourth 4 bytes is the column count
            column_count = int.from_bytes(f.read(4), 'big')
            # rest is the image pixel data, each pixel is stored as an unsigned byte
            # pixel values are 0 to 255
            image_data = f.read()
            train_images = np.frombuffer(image_data, dtype=np.uint8)\
                .reshape((image_count, row_count, column_count))
            to_return.append(np.where(train_images > 127, 1, 0))

    if test_data:
        with gzip.open('data/mnist/t10k-images-idx3-ubyte.gz', 'r') as f:
            # first 4 bytes is a magic number
            magic_number = int.from_bytes(f.read(4), 'big')
            # second 4 bytes is the number of images
            image_count = int.from_bytes(f.read(4), 'big')
            # third 4 bytes is the row count
            row_count = int.from_bytes(f.read(4), 'big')
            # fourth 4 bytes is the column count
            column_count = int.from_bytes(f.read(4), 'big')
            # rest is the image pixel data, each pixel is stored as an unsigned byte
            # pixel values are 0 to 255
            image_data = f.read()
            test_images = np.frombuffer(image_data, dtype=np.uint8)\
                .reshape((image_count, row_count, column_count))
            to_return.append(np.where(test_images > 127, 1, 0))
    arr_return = np.array(to_return[0])
    return arr_return


def get_labels(train_data=True, test_data=False):
    to_return = []
    if train_data:
        with gzip.open('data/mnist/train-labels-idx1-ubyte.gz', 'r') as f:
            # first 4 bytes is a magic number
            magic_number = int.from_bytes(f.read(4), 'big')
            # second 4 bytes is the number of labels
            label_count = int.from_bytes(f.read(4), 'big')
            # rest is the label data, each label is stored as unsigned byte
            # label values are 0 to 9
            label_data = f.read()
            train_labels = np.frombuffer(label_data, dtype=np.uint8)
            to_return.append(train_labels)
    if test_data:
        with gzip.open('data/mnist/t10k-labels-idx1-ubyte.gz', 'r') as f:
            # first 4 bytes is a magic number
            magic_number = int.from_bytes(f.read(4), 'big')
            # second 4 bytes is the number of labels
            label_count = int.from_bytes(f.read(4), 'big')
            # rest is the label data, each label is stored as unsigned byte
            # label values are 0 to 9
            label_data = f.read()
            test_labels = np.frombuffer(label_data, dtype=np.uint8)
            to_return.append(test_labels)
    arr_return = np.array(to_return[0])
    return arr_return

load_mnist(train_data=True, test_data=True)

train_images = get_images(train_data=True, test_data=False)
test_images = get_images(train_data=False, test_data=True)
train_lables = get_labels(train_data=True, test_data=False)
test_lables = get_labels(train_data=False, test_data=True)

from matplotlib import pyplot
for i in range(9):  
  pyplot.subplot(330 + 1 + i)
  pyplot.imshow(train_images[i], cmap=pyplot.get_cmap('gray'))
  pyplot.show()

def imgtodf(img):
  arr = np.empty((0 ,784), int)
  for i in img:
    array_1d = np.array(i).flatten()
    array_1d = array_1d.reshape(1,784)
    arr = np.append(arr, np.array(array_1d), axis=0)
    df = pd.DataFrame(arr)
    print
  return df

xtrain = pd.read_csv('/content/drive/MyDrive/pattern//Train.csv')
xtest = pd.read_csv('/content/drive/MyDrive/pattern//Test.csv')

ytrain = pd.DataFrame(train_lables)
ytest =  pd.DataFrame(test_lables)

print(xtrain.shape)
print(xtest.shape)
print(ytrain.shape)
print(ytest.shape)

"""### **rbf  , C=10 , gamma = 0.1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# classifier = SVC(kernel='rbf', C = 10, gamma = 0.1   , random_state=1)
# classifier.fit(xtrain,ytrain)
# ypred_rbf = classifier.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_rbf))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_rbf))

#precision
print('Precision:' ,  precision_score(ytest, ypred_rbf, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_rbf, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_rbf, average= 'weighted'))

"""### **rbf , C = 10**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# classifier = SVC(kernel='rbf', C = 10 , random_state=1)
# classifier.fit(xtrain,ytrain)
# ypred_rbf = classifier.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_rbf))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_rbf))

#precision
print('Precision:' ,  precision_score(ytest, ypred_rbf, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_rbf, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_rbf, average= 'weighted'))

"""### **rbf , C = 0.1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# classifier = SVC(kernel='rbf', C = 0.1  , random_state=1)
# classifier.fit(xtrain,ytrain)
# ypred_rbf = classifier.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_rbf))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_rbf))

#precision
print('Precision:' ,  precision_score(ytest, ypred_rbf, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_rbf, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_rbf, average= 'weighted'))

"""### **rbf , C = 1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# classifier = SVC(kernel='rbf', C = 1   , random_state=1)
# classifier.fit(xtrain,ytrain)
# ypred_rbf = classifier.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_rbf))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_rbf))

#precision
print('Precision:' ,  precision_score(ytest, ypred_rbf, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_rbf, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_rbf, average= 'weighted'))

"""### **linear , C  = 1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clftotal = make_pipeline(StandardScaler(),
#                      LinearSVC(random_state=0))
# clftotal.fit(xtrain, ytrain)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ypred_linear = clftotal.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_linear))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_linear))

#precision
print('Precision:' ,  precision_score(ytest, ypred_linear, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_linear, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_linear, average= 'weighted'))

"""### **linear , C = 10**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clftotal = make_pipeline(StandardScaler(),
#                      LinearSVC(random_state=0,C=10))
# clftotal.fit(xtrain, ytrain)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ypred_linear = clftotal.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_linear))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_linear))

#precision
print('Precision:' ,  precision_score(ytest, ypred_linear, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_linear, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_linear, average= 'weighted'))

"""### **linear , C = 0.1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clftotal = make_pipeline(StandardScaler(),
#                      LinearSVC(random_state=0,C=0.1, tol=1e-5))
# clftotal.fit(xtrain, ytrain)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ypred_linear = clftotal.predict(xtest)
# print("Accuracy:", metrics.accuracy_score(ytest, ypred_linear))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, ypred_linear))

#precision
print('Precision:' ,  precision_score(ytest, ypred_linear, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, ypred_linear, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,ypred_linear, average= 'weighted'))

"""### **poly , C = 1 , degree = 2**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=1, degree=2)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 0.1 , degree = 2**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=0.1, degree=2)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 10 , degree = 2**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=10, degree=2)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 10 , degree = 3**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=10, degree=3)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 1 , degree = 3**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=1, degree=3)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 0.1 , degree = 3**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=0.1, degree=3)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 10 , degree = 4**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=10, degree=4)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 1 , degree = 4**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=1, degree=4)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **poly , C = 0.1 , degree = 4**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# polycl = SVC(kernel='poly', C=0.1, degree=4)
# polycl.fit(xtrain,ytrain)

poly_ypred = polycl.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, poly_ypred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, poly_ypred))

#precision
print('Precision:' ,  precision_score(ytest, poly_ypred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, poly_ypred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,poly_ypred, average= 'weighted'))

"""### **sigmoid , C = 1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# sig_class = SVC(kernel='sigmoid', C=1 , random_state=1)
# sig_class.fit(xtrain ,ytrain)

sig_pred = sig_class.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, sig_pred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, sig_pred))

#precision
print('Precision:' ,  precision_score(ytest, sig_pred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, sig_pred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,sig_pred, average= 'weighted'))

"""### **sigmoid , C = 10**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# sig_class = SVC(kernel='sigmoid', C=10 , random_state=1)
# sig_class.fit(xtrain ,ytrain)

sig_pred = sig_class.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, sig_pred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, sig_pred))

#precision
print('Precision:' ,  precision_score(ytest, sig_pred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, sig_pred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,sig_pred, average= 'weighted'))

"""### **sigmoid , C = 0.1**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# sig_class = SVC(kernel='sigmoid', C=0.1 , random_state=1)
# sig_class.fit(xtrain ,ytrain)

sig_pred = sig_class.predict(xtest)
print("Accuracy:", metrics.accuracy_score(ytest, sig_pred))

#confusion matrix
print('confusion ' , confusion_matrix(ytest, sig_pred))

#precision
print('Precision:' ,  precision_score(ytest, sig_pred, average='weighted'))


#recall

print('Recal :' , recall_score(ytest, sig_pred, average='weighted'))


#f1 score
print('f1 score  ' , f1_score(ytest,sig_pred, average= 'weighted'))

"""# **Section 3**"""

!gdown --id 1mQhnAAP5djmRjmN5rC7KI_-L537Z5Iva

!unrar x './persian_LPR.rar'

def dataframeproducer(path , label):
  list1 = []
  dim = (1 , 256 )
  for i in glob.glob(path) :
    image = cv.imread(i , 0) 
    image = cv.resize(image , dim)
    list1.append(image)
  num = np.asarray(list1)
  result = num[:, :, 0]
  # print(result.shape)
  df = pd.DataFrame(result)
  # # df['target'] = label
  df['target'] = label
  return df

pic2 = dataframeproducer('./2/*.bmp','2')
pic3 = dataframeproducer('./3/*.bmp','3')
pic7 = dataframeproducer('./7/*.bmp','7')
picS = dataframeproducer('./S/*.bmp','s')
picw = dataframeproducer('./W/*.bmp','w')

columns = [pic2, pic3, pic7, picS, picw]
dataset = pd.concat(columns)
dataset = dataset.sample(frac=1).reset_index(drop=True)
dataset

x = dataset.drop('target', axis=1).values.astype('float32') / 255
y = dataset.target.values

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=1)

model_sec3 = SVC(kernel='rbf' , C = 10 )
model_sec3.fit(xtrain, ytrain)
ypred = model_sec3.predict(xtest)
print("Accuracy is :", metrics.accuracy_score(ytest, ypred))

scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']
cross_val = KFold(n_splits = 5, random_state=1, shuffle=True)
model = SVC(kernel='rbf', C=10)
print(cross_validate(model, xtrain, ytrain, scoring=scoring, cv=cross_val))